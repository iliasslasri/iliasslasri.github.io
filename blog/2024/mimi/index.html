<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Mimi: The Codec behind Moshi and Unmute | Iliass Lasri </title> <meta name="author" content="Iliass Lasri"> <meta name="description" content="A deep dive into Kyutai's state-of-the-art neural audio codec, exploring its architecture, quantization, and integration with LLMs."> <meta name="keywords" content="Audio DSP, Audio ML"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iliasslasri.github.io/blog/2024/mimi/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Iliass</span> Lasri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects &amp; hackathons </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Mimi: The Codec behind Moshi and Unmute</h1> <p class="post-meta"> Created on July 20, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/audio"> <i class="fa-solid fa-hashtag fa-sm"></i> audio</a>   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> ai</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/codecs"> <i class="fa-solid fa-hashtag fa-sm"></i> codecs</a>   ·   <a href="/blog/category/technology"> <i class="fa-solid fa-tag fa-sm"></i> technology</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><img src="../img/mimi_arch.avif" alt="Mimi architecture diagram"></p> <p><a href="https://kyutai.org/Moshi.pdf" rel="external nofollow noopener" target="_blank">Official Paper</a> for reference. Minimal environment setup to use Mimi can be found <a href="https://github.com/iliasslasri/mimi" rel="external nofollow noopener" target="_blank">in my repo</a>.</p> <h2 id="the-scope-of-this-post">The Scope of this Post</h2> <p>Today we are going to explore Mimi, a state-of-the-art neural audio codec developed by Kyutai. We will compare audio quality before and after Mimi processing, and we will then study how Mimi works and what types of outputs it produces.</p> <h2 id="what-is-mimi">What is Mimi?</h2> <blockquote> <p>“Mimi codec is a state-of-the-art audio neural codec, developed by Kyutai, that combines semantic and acoustic information into audio tokens running at 12Hz and a bitrate of 1.1kbps.”</p> </blockquote> <p>This is the official description of Mimi from Kyutai’s Huggingface repo. Mimi is also the neural audio codec that powers Moshi (a demo is currently available on <a href="https://moshi.chat" rel="external nofollow noopener" target="_blank">moshi.chat</a>), which we may discuss in a future post.</p> <h2 id="what-is-a-neural-audio-codec">What is a Neural Audio Codec?</h2> <p>First, let’s define a codec: A codec, short for “coder-decoder” or “compressor-decompressor”, is a device or computer program that encodes or decodes a digital data stream or signal.</p> <p>The primary purposes of codecs are to:</p> <ul> <li>Reduce file size for efficient storage</li> <li>Decrease bandwidth requirements for transmission</li> <li>Maintain an acceptable level of quality</li> </ul> <p>An audio codec is a codec that encodes or decodes audio data. There exist two types of audio codecs:</p> <ul> <li> <strong>Lossy audio codecs:</strong> These compress audio by removing some data, resulting in smaller file sizes but with some loss in quality (e.g., MP3, AAC).</li> <li> <strong>Lossless audio codecs:</strong> These compress audio without losing any original data, maintaining perfect quality but with larger file sizes compared to lossy codecs (e.g., FLAC, ALAC).</li> </ul> <p>A neural audio codec is a type of audio codec that leverages DNNs, neural networks in particular, to compress and decompress audio signals. Some examples include:</p> <ul> <li> <strong>Lyra:</strong> Developed by Google, designed for low-bitrate speech compression.</li> <li> <strong>EnCodec:</strong> Created by Meta AI, a high-fidelity neural audio codec.</li> <li> <strong>SoundStream:</strong> Another Google codec focusing on high-quality audio compression at low bitrates.</li> </ul> <p>Mimi’s architecture is mostly derived from SoundStream and EnCodec, as stated in the <a href="https://kyutai.org/Moshi.pdf" rel="external nofollow noopener" target="_blank">official paper</a>, although it has some novel features that set it apart.</p> <h2 id="mimi-in-detail">Mimi in Detail</h2> <p>As mentioned earlier, Mimi is a neural audio codec that combines semantic and acoustic information into audio tokens running at 12Hz and a bitrate of 1.1kbps.</p> <p>However, there is a slight discrepancy: the actual implementation of Mimi runs at <strong>12.5Hz</strong>, as stated in the paper and in the official <code class="language-plaintext highlighter-rouge">config.json</code> file (under <code class="language-plaintext highlighter-rouge">frame_rate</code>). Apart from that, Mimi is a fascinating codec that produces high-quality audio at an incredibly low bitrate.</p> <p>Being an audio codec, Mimi is composed of two main components which form a bottleneck architecture:</p> <ol> <li> <strong>An encoder:</strong> Takes an audio signal as input and compresses it into a smaller representation.</li> <li> <strong>A decoder:</strong> Takes the compressed representation and reconstructs the audio signal.</li> </ol> <h3 id="the-encoding-process">The Encoding Process</h3> <p>The encoder compresses the audio signal into a sequence of audio codes, split into semantic and acoustic audio tokens. Here’s how it works:</p> <ul> <li>The audio signal is split into frames, each lasting 0.08 seconds (12.5Hz frame rate).</li> <li>Each frame is passed through a convolutional neural network (CNN) and a transformer, which convert the frame into a vector of length 512.</li> <li>This vector is then passed through 8 quantizers.</li> </ul> <p>These quantizers produce 1 token per frame each:</p> <ul> <li> <strong>1 quantizer</strong> for the semantic tokens. These represent the content/meaning of the audio and are trained to replicate semantic information obtained from a WavLM self-supervised audio model.</li> <li> <strong>7 quantizers</strong> (according to the paper) for the acoustic tokens, which capture the style and details of the audio.</li> </ul> <p>The quantized audio tokens are concatenated to produce a tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size, num_quantizers, sample_rate * length_audio)</code>.</p> <h3 id="bitrate-calculation">Bitrate Calculation</h3> <p>Let’s calculate the bitrate of Mimi based on the information provided using the following parameters:</p> <ul> <li>Frame rate: \(12.5 \text{ Hz}\)</li> <li>Number of audio tokens per frame: \(8\)</li> <li>Number of bits per audio token: \(\log_2(2048) = 11\) (since there are 2048 possible audio tokens)</li> </ul> <p>Therefore, the bitrate calculation is:</p> \[12.5 \times 8 \times 11 = 1100 \text{ bps} \text{ (or } 1.1 \text{ kbps)}\] <p><em>Note: Here we find another discrepancy. The paper states that there are 8 audio tokens per frame, but the official implementation produces 32 audio tokens per frame, and we can even set the number of levels in RQV as specified in <a href="https://github.com/kyutai-labs/moshi/issues/122" rel="external nofollow noopener" target="_blank">issue #122</a>.</em></p> <h3 id="the-decoding-process">The Decoding Process</h3> <p>The decoder takes the quantized tokens and reconstructs the audio signal following these steps:</p> <ol> <li>The tokens are passed through an inverse quantization process.</li> <li>The resulting embeddings are processed by another transformer network.</li> <li>Finally, a decoder CNN (mirroring the encoder’s CNN) reconstructs the audio waveform.</li> </ol> <h2 id="applications-of-mimi">Applications of Mimi</h2> <p>Mimi was primarily developed to power <strong>Moshi</strong>, a speech-to-speech AI model.</p> <p>Current chat models (like GPT) primarily operate on text tokens—discrete numerical representations of words. These models aren’t inherently designed to process audio data. Mimi bridges this gap by converting audio into discrete tokens, similar to how text is tokenized.</p> <p>This clever approach allows text-only models to support audio understanding and generation without requiring a complete overhaul of their architecture. Theoretically, we could fine-tune existing text-trained models to work with audio by teaching them to interpret these audio tokens alongside text tokens.</p> <h2 id="conclusions">Conclusions</h2> <p>Mimi represents a significant step forward in the field of neural audio codecs. Its ability to compress audio to incredibly low bitrates while maintaining good quality is impressive. The separation of semantic and acoustic information into distinct tokens is a novel approach that opens up new possibilities for audio processing.</p> <p>Using RQV is also a novel approach for quantization in codecs; check this for an implementation of RQV in <a href="https://github.com/lucidrains/vector-quantize-pytorch" rel="external nofollow noopener" target="_blank">PyTorch</a>.</p> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>