<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PESTO (VQT, Losses &amp; Eval on reverb) | Iliass Lasri </title> <meta name="author" content="Iliass Lasri"> <meta name="description" content="Pitch Estimation with Self-supervised Transposition-Equivariant Objective"> <meta name="keywords" content="Audio DSP, Audio ML"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iliasslasri.github.io/blog/2026/pesto/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Iliass</span> Lasri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects &amp; hackathons </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">PESTO (VQT, Losses &amp; Eval on reverb)</h1> <p class="post-meta"> Created on January 02, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/signal-processing"> <i class="fa-solid fa-hashtag fa-sm"></i> signal-processing</a>   <a href="/blog/tag/audio"> <i class="fa-solid fa-hashtag fa-sm"></i> audio</a>   <a href="/blog/tag/mir"> <i class="fa-solid fa-hashtag fa-sm"></i> mir</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   ·   <a href="/blog/category/explanation"> <i class="fa-solid fa-tag fa-sm"></i> explanation</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="i-vqt">I. VQT</h1> <h2 id="1-what-is-the-cqtvqt">1. What is the CQT/VQT?</h2> <p>The <strong>Constant-Q Transform (CQT)</strong> is a time-frequency representation of an audio signal. Unlike the Short-Time Fourier Transform (STFT), which has a fixed frequency resolution (linear frequency spacing), the CQT has a logarithmic frequency spacing.</p> <p>This means:</p> <ul> <li> <strong>Low frequencies</strong> are analyzed with high frequency resolution (narrow bandwidth filters) but poor time resolution, requires large analysis window. Note that this can be limitation in real time inference.</li> <li> <strong>High frequencies</strong> are analyzed with low frequency resolution (wide bandwidth filters) but high time resolution.</li> <li>The ratio of center frequency to bandwidth ($Q$) remains <strong>constant</strong> for all bins.</li> </ul> <p>This structure mimics the human auditory system and the musical scale, where notes are spaced logarithmically (e.g., octaves are powers of 2).</p> <p>The center frequency for the $k$-th bin, denoted as $f_k$, follows a geometric progression:</p> \[f_k = f_{min} \cdot 2^{\frac{k}{B}}\] <p>Where:</p> <ul> <li>$k = 1, 2, …, K$ is the bin index.</li> <li>$f_{min}$ is the lowest center frequency (e.g., 27.5 Hz for the lowest piano note A0).</li> <li>$B$ is the number of bins per octave (frequency resolution).</li> </ul> <p>The <em>VQT</em> differs from the CQT y adding a parameter γ, which smoothly decreases the Q factors of the analysis filters for low frequencies, so since the Q factor is reduced for low freqs, this reduces the window lenght for these low frequencies allowing for higher frame rate.</p> <h3 id="2-key-variables-in-cqtvqt">2. Key Variables in CQT/VQT</h3> <table> <thead> <tr> <th style="text-align: left">Variable</th> <th style="text-align: left"> </th> <th style="text-align: left">Definition &amp; Formula</th> <th style="text-align: left">Typical Value</th> <th style="text-align: left">Significance &amp; Impact</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>$f_{min}$</strong></td> <td style="text-align: left"><strong>Minimum Frequency</strong></td> <td style="text-align: left">The center frequency of the very first bin.</td> <td style="text-align: left"> <strong>27.5 Hz</strong> (A0 on piano)</td> <td style="text-align: left">It sets the “anchor” for the entire logarithmic scale.</td> </tr> <tr> <td style="text-align: left"><strong>$B$</strong></td> <td style="text-align: left"><strong>Bins per Octave</strong></td> <td style="text-align: left">Defines the resolution of the transform (frequency bands per octave).<br>If $b$ is bins per semitone*, then $B = 12 \times b$.</td> <td style="text-align: left"> <strong>$B=36$</strong> ($b=3$)</td> <td style="text-align: left">Higher $B$ gives better frequency precision but requires longer computation windows, resulting in worse time precision.</td> </tr> <tr> <td style="text-align: left"><strong>$Q$</strong></td> <td style="text-align: left"><strong>Quality Factor</strong></td> <td style="text-align: left">The ratio of a filter’s center frequency to its bandwidth (constant for all $k$).<br>Formula: \(Q = \frac{f_k}{\Delta f_k} = \frac{1}{2^{1/B} - 1}\)</td> <td style="text-align: left">Dependent on $B$</td> <td style="text-align: left">This constant ratio ensures that if you go up an octave, the bandwidth also doubles, keeping the “musical” resolution consistent.</td> </tr> <tr> <td style="text-align: left"><strong>$w_k$</strong></td> <td style="text-align: left"><strong>Window Length</strong></td> <td style="text-align: left">The length of the analysis window (in samples) for bin $k$.<br>Formula: \(w_k = \frac{f_s}{f_k} \cdot Q\)</td> <td style="text-align: left">Varies with $f_k$</td> <td style="text-align: left"> <strong>Low freq:</strong> Very long window (high freq resolution).<br><strong>High freq:</strong> Very short window (high time resolution).<br>This variation is the main difference from STFT.</td> </tr> <tr> <td style="text-align: left"><strong>$\gamma$</strong></td> <td style="text-align: left"><strong>Gamma</strong></td> <td style="text-align: left">A parameter in <strong>VQT</strong> to limit window length at low frequencies.<br>Formula: \(w_k = \left\lceil \frac{Q \cdot f_s}{f_k + \frac{\gamma}{\zeta}} \right\rceil\)</td> <td style="text-align: left"><strong>$\gamma=7$</strong></td> <td style="text-align: left"> <strong>If $\gamma = 0$:</strong> It is a standard CQT.<br><strong>If $\gamma &gt; 0$:</strong> Bandwidths at low frequencies are artificially widened (reducing $Q$) to prevent excessive window lengths. This improves time resolution and speed.</td> </tr> </tbody> </table> <p><em>*Note: A semitone is the smallest standard musical interval in Western music, representing the distance between two adjacent notes on a piano.</em></p> <h2 id="3-the-transform-steps">3. The Transform Steps</h2> <h4 id="a-constructing-the-filters-kernels">a. Constructing the Filters (Kernels)</h4> <p>The CQT is essentially a <strong>filter bank</strong>. We need to construct a separate complex filter (kernel) for every frequency bin $k$.</p> <h5 id="step-a-determine-window-lengths">Step A: Determine Window Lengths</h5> <p>First, for each bin $k$, we calculate the specific window length $N_k$ (in samples). This depends on whether we are using CQT or VQT.</p> <ul> <li> <strong>For CQT ($\gamma = 0$):</strong> \(N_k = \frac{f_s}{f_k} \cdot Q\)</li> <li> <strong>For VQT ($\gamma &gt; 0$):</strong> \(N_k = \left\lceil \frac{f_s \cdot Q}{f_k + \frac{\gamma}{\zeta}} \right\rceil\)</li> </ul> <p><em>(Recall that $Q = (2^{1/B} - 1)^{-1}$ and $f_k = f_{min} \cdot 2^{k/B}$)</em>.</p> <h5 id="step-b-the-time-domain-kernel-expression">Step B: The Time-Domain Kernel Expression</h5> <p>The filter $h_k[n]$ for the $k$-th bin is a complex sinusoid modulated by a window function. It is constructed as follows:</p> \[h_k[n] = \frac{1}{C_k} \cdot w\left(\frac{n}{N_k}\right) \cdot e^{-j 2 \pi \frac{f_k}{f_s} n}\] <p>Where:</p> <ul> <li> <strong>$n$</strong>: The time sample index, centered around zero, typically ranging from $-\lfloor \frac{N_k}{2} \rfloor$ to $+\lfloor \frac{N_k}{2} \rfloor$.</li> <li> <strong>$e^{-j 2 \pi \dots}$</strong>: The complex exponential (sinusoid) that “tunes” this filter to detect frequency $f_k$.</li> <li> <strong>$w(t)$</strong>: A window function (typically a <strong>Hamming</strong> or <strong>Hann</strong> window) centered at 0. This limits the filter in time and reduces spectral leakage.</li> <li> <strong>$C_k$</strong>: A normalization constant (usually the $L_2$ norm or $L_1$ norm of the window) to ensuring energy is preserved across different bin widths.</li> </ul> <p>In implementations like <code class="language-plaintext highlighter-rouge">nnAudio</code> (used in PESTO), these kernels are <strong>pre-computed</strong> and stored as weights in a 1D Convolutional layer.</p> <hr> <h4 id="b-performing-the-transform">b. Performing the Transform</h4> <p>Once the bank of filters ${h_k}$ is constructed for all $k = 1 \dots K$, the transform is performed via <strong>convolution</strong>.</p> <h5 id="the-expression">The Expression</h5> <p>For an input audio signal $x[n]$, the CQT coefficient $X[k, n]$ for bin $k$ at time $n$ is the result of convolving the signal with the complex conjugate of the time-reversed filter kernel:</p> \[X[k, n] = \sum_{m} x[m] \cdot h_k^*[m - n]\] <p>In practice, this is equivalent to running the audio through a 1D Convolutional Neural Network layer where:</p> <ul> <li> <strong>Input:</strong> The raw audio waveform (size $1 \times T$).</li> <li> <strong>Weights:</strong> The pre-computed CQT kernels (size $K \times \text{max}(N_k)$).</li> <li> <strong>Output:</strong> The complex CQT spectrogram.</li> </ul> <hr> <h1 id="ii-loss-functions">II. Loss Functions</h1> <p>PESTO minimizes a composite objective function that combines three distinct losses to enforce physical equivariance while preventing model collapse.</p> <h4 id="1-equivariance-loss-mathcall_textequiv">1. Equivariance Loss ($\mathcal{L}_{\text{equiv}}$)</h4> <p><strong>Purpose:</strong> Enforces the geometric property that a pitch shift in the input must result in a proportional shift in the output probability distribution.</p> <p>Instead of using a decoder, PESTO projects the output distribution $y$ onto a scalar using a deterministic linear form $\phi$. If $y^{(k)}$ is a valid $k$-transposition of $y$, the ratio of their projections must equal $\alpha^k$ (where $\alpha = 2^{1/36}$ in practice).</p> <p>The loss minimizes the error between the actual projected ratio and the expected ratio using the Huber loss function $h_\tau$ for robustness:</p> \[\mathcal{L}_{\text{equiv}}(y, y^{(k)}, k) = h_\tau \left( \frac{\phi(y^{(k)})}{\phi(y)} - \alpha^k \right)\] <h4 id="2-shifted-cross-entropy-loss-mathcall_textsce">2. Shifted Cross-Entropy Loss ($\mathcal{L}_{\text{SCE}}$)</h4> <p><strong>Purpose:</strong> Acts as a regularization term to enforce the shape of the distribution and prevent the model from satisfying equivariance trivially (e.g., by outputting flat distributions).</p> <p>This loss explicitly compares the original output $y$ against the shifted output $y^{(k)}$. Since a shift of $k$ bins moves some indices out of the viewable frame, these “out-of-bounds” indices are replaced by 0 (masked). This ensures the model is not penalized for pitches that disappear from the frequency range due to the shift.</p> \[\mathcal{L}_{\text{SCE}}(y, y^{(k)}, k) = \sum_{i=0}^{d-1} y_i \log(y^{(k)}_{i+k})\] <p><em>(Note: Indices $i+k$ that fall outside the valid range $[0, d-1]$ are ignored in the sum)</em>.</p> <h4 id="3-invariance-loss-mathcall_textinv">3. Invariance Loss ($\mathcal{L}_{\text{inv}}$)</h4> <p><strong>Purpose:</strong> Ensures the model predicts pitch based on frequency content rather than timbre or loudness.</p> <p>We generates augmented views $\tilde{x}$ of the input $x$ using pitch-preserving transforms (gain, additive white noise, or background mixing). The loss then minimizes the standard cross-entropy between the predictions of the original and augmented views.</p> \[\mathcal{L}_{\text{inv}}(y, \tilde{y}) = \text{CrossEntropy}(y, \tilde{y})\] <h2 id="loss-symmetry--gradient-stopping">Loss Symmetry &amp; Gradient Stopping</h2> <p>The PESTO loss function incorporates three critical mechanisms to ensure effective SSL: <strong>Symmetry</strong>, <strong>Stop Gradient</strong> and <strong>Loss Weighting</strong>.</p> <h4 id="1-why-losses-should-be-symmetric">1. Why losses should be symmetric</h4> <p>Since PESTO is self-supervised, there is no “ground truth” label. The model learns by comparing two different augmented views of the same input (e.g., $y$ and $\tilde{y}$), and standard Cross-Entropy $\text{Loss}(A, B)$ is directional, it assumes $B$ is the truth and optimizes $A$ to match it. So to treat both views equally, the loss is calculated in both directions and averaged. This ensures the model learns a robust representation regardless of which augmented view is presented as the “target.”</p> \[\text{Loss} = \frac{1}{2} \left[ \underbrace{\mathcal{L}(y, \tilde{y})}_{\text{Predict } y \text{ from } \tilde{y}} + \underbrace{\mathcal{L}(\tilde{y}, y)}_{\text{Predict } \tilde{y} \text{ from } y} \right]\] <h4 id="2-why-stop-gradient-is-used">2. Why stop gradient is used</h4> <p>The “Stop Gradient” operation is a stability mechanism widely used in Siamese networks (like SimSiam or BYOL) to prevent Model Collapse.</p> <p>If the network updates its parameters to minimize the distance between $y$ and $\tilde{y}$ simultaneously, it may converge on a “lazy” solution, so the network could learn to output a constant vector (e.g., all zeros or a uniform distribution) for every input. If $y = \tilde{y} = \text{constant}$, the loss is zero, but the model has learned nothing about pitch. That’s why we artificially freeze one side of the equation during backpropagation.</p> <ul> <li>In the term $\mathcal{L}(y, \text{sg}(\tilde{y}))$, $\tilde{y}$ is treated as a <strong>fixed constant</strong>.</li> <li>The network only updates weights to move $y$ closer to $\tilde{y}$, not to move $\tilde{y}$ closer to $y$.</li> <li> <strong>Result:</strong> This prevents the degenerate scenario where both outputs simply “meet in the middle” at a meaningless value, forcing the network to learn meaningful transformations.</li> </ul> <h4 id="3-adaptive-loss-weighting">3. Adaptive Loss Weighting</h4> <p>If one loss is numerically much larger than the others, the model will focus only on that one and ignore the others, and since we are not sure that the three losses have the same scales and gradients. To balance the three competing objectives, PESTO does not use fixed hyperparameters. Instead, it employs <strong>GradNorm</strong>, a gradient-based normalization algorithm, since the norm of the gradient of each loss can be interpreted as its contribution to the total objective to optimize.. Refer to the two papers: <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf" rel="external nofollow noopener" target="_blank">Taming Transformers for High-Resolution Image Synthesis</a> and <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/4eb2c0adafbe71269f3a772c130f9e53-Paper-Conference.pdf" rel="external nofollow noopener" target="_blank">Value Function Decomposition for Iterative Design of Reinforcement Learning Agents</a>.</p> <h2 id="iii-experimental-results--robustness">III. Experimental Results &amp; Robustness</h2> <p>my work extended the original PESTO evaluation to include <strong>Environmental Robustness</strong> (Reverberation).</p> <h3 id="robustness-to-reverberation">Robustness to Reverberation</h3> <p>To evaluate how PESTO performs in real-world acoustic environments, we subjected the model to synthetic reverberation. This simulates the effect of sound reflections in a physical space, which can obscure the fundamental frequency.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/reverb_filter-480.webp 480w,/assets/img/reverb_filter-800.webp 800w,/assets/img/reverb_filter-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/reverb_filter.png" class="img-fluid" width="100%" height="auto" title="Comparaison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4 id="quantitative-analysis">Quantitative Analysis</h4> <p>We tested the model using two datasets—<strong>MIR-1K</strong> (singing voice) and <strong>MDB</strong> (musical instruments)—under varying reverb mix levels.</p> <table> <thead> <tr> <th>Mix</th> <th>RPA (MIR-1K)</th> <th>RPA (MDB)</th> <th>RCA (MIR-1K)</th> <th>RCA (MDB)</th> </tr> </thead> <tbody> <tr> <td><strong>0.0 (Clean)</strong></td> <td>86.92%</td> <td>88.21%</td> <td>87.19%</td> <td>92.25%</td> </tr> <tr> <td><strong>0.3 (Mild)</strong></td> <td>83.56%</td> <td>83.28%</td> <td>83.83%</td> <td>88.62%</td> </tr> <tr> <td><strong>0.6 (Heavy)</strong></td> <td><strong>69.32%</strong></td> <td><strong>69.78%</strong></td> <td>70.13%</td> <td>76.11%</td> </tr> <tr> <td><strong>0.9 (Extreme)</strong></td> <td>59.61%</td> <td>62.87%</td> <td>60.50%</td> <td>69.13%</td> </tr> </tbody> </table> <ul> <li> <strong>Stability:</strong> The model is remarkably stable under mild reverb conditions.</li> <li> <strong>Degradation:</strong> A sharp performance drop occurs at , where the reflections begin to dominate the direct signal.</li> </ul> <h4 id="qualitative-error-analysis">Qualitative Error Analysis</h4> <p>When examining the predictions at extreme reverb levels, we observed specific failure modes:</p> <div class="row"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pesto_0.9-480.webp 480w,/assets/img/pesto_0.9-800.webp 800w,/assets/img/pesto_0.9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/pesto_0.9.png" class="img-fluid" width="100%" height="auto" title="Comparaison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <strong>Octave Errors:</strong> Reverb tails often create constructive interference at higher harmonics. If the second harmonic becomes more energetic than the fundamental due to reflections, the model may mistakenly track the higher octave.</li> <li> <strong>Temporal Smearing:</strong> Reverberation causes spectral energy to persist long after the note has ended. This “smearing” creates misalignment between the actual pitch and the model’s prediction.</li> <li> <strong>Structural Limitations:</strong> Because PESTO’s architecture relies on <strong>1D-convolutions along the frequency axis</strong>, it processes frames independently. It lacks the <strong>temporal memory</strong> (e.g., recurrent layers or attention) necessary to distinguish between a new note and the “echo” of a previous one.</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoyed Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/resources/">A Curated Collection of AI &amp; Audio Resources</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/nmf/">NMF Divergence Derivation by ME</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/mimi/">Mimi: The Codec behind Moshi and Unmute</a> </li> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>