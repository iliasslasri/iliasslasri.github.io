---
layout: post
title: PESTO (VQT, Losses & Eval on reverb)
date: 2026-01-02 12:00:00 +0100
description: Pitch Estimation with Self-supervised Transposition-Equivariant Objective
tags: signal-processing audio mir  deep-learning
categories: explanation
related_posts: true
---

# I. VQT
## 1. What is the CQT/VQT?

The **Constant-Q Transform (CQT)** is a time-frequency representation of an audio signal. Unlike the Short-Time Fourier Transform (STFT), which has a fixed frequency resolution (linear frequency spacing), the CQT has a logarithmic frequency spacing.

This means:
* **Low frequencies** are analyzed with high frequency resolution (narrow bandwidth filters) but poor time resolution, requires large analysis window. Note that this can be limitation in real time inference.
* **High frequencies** are analyzed with low frequency resolution (wide bandwidth filters) but high time resolution.
* The ratio of center frequency to bandwidth ($Q$) remains **constant** for all bins.

This structure mimics the human auditory system and the musical scale, where notes are spaced logarithmically (e.g., octaves are powers of 2).

The center frequency for the $k$-th bin, denoted as $f_k$, follows a geometric progression:

$$
f_k = f_{min} \cdot 2^{\frac{k}{B}}
$$

Where:
* $k = 1, 2, ..., K$ is the bin index.
* $f_{min}$ is the lowest center frequency (e.g., 27.5 Hz for the lowest piano note A0).
* $B$ is the number of bins per octave (frequency resolution).

The *VQT* differs from the CQT y adding a parameter γ, which smoothly decreases the Q factors of the analysis filters for low frequencies, so since the Q factor is reduced for low freqs, this reduces the window lenght for these low frequencies allowing for higher frame rate.

### 2. Key Variables in CQT/VQT

| Variable |  | Definition & Formula | Typical Value | Significance & Impact |
| :--- | :--- | :--- | :--- | :--- |
| **$f_{min}$** | **Minimum Frequency** | The center frequency of the very first bin. | **27.5 Hz** (A0 on piano)  | It sets the "anchor" for the entire logarithmic scale. |
| **$B$** | **Bins per Octave** | Defines the resolution of the transform (frequency bands per octave).<br>If $b$ is bins per semitone*, then $B = 12 \times b$. | **$B=36$** ($b=3$)| Higher $B$ gives better frequency precision but requires longer computation windows, resulting in worse time precision. |
| **$Q$** | **Quality Factor** | The ratio of a filter's center frequency to its bandwidth (constant for all $k$).<br>Formula: $$Q = \frac{f_k}{\Delta f_k} = \frac{1}{2^{1/B} - 1}$$ | Dependent on $B$ | This constant ratio ensures that if you go up an octave, the bandwidth also doubles, keeping the "musical" resolution consistent. |
| **$w_k$** | **Window Length** | The length of the analysis window (in samples) for bin $k$.<br>Formula: $$w_k = \frac{f_s}{f_k} \cdot Q$$ | Varies with $f_k$ | **Low freq:** Very long window (high freq resolution).<br>**High freq:** Very short window (high time resolution).<br>This variation is the main difference from STFT. |
| **$\gamma$** | **Gamma** | A parameter in **VQT** to limit window length at low frequencies.<br>Formula: $$w_k = \left\lceil \frac{Q \cdot f_s}{f_k + \frac{\gamma}{\zeta}} \right\rceil$$ | **$\gamma=7$**  | **If $\gamma = 0$:** It is a standard CQT.<br>**If $\gamma > 0$:** Bandwidths at low frequencies are artificially widened (reducing $Q$) to prevent excessive window lengths. This improves time resolution and speed. |

*\*Note: A semitone is the smallest standard musical interval in Western music, representing the distance between two adjacent notes on a piano.*

## 3. The Transform Steps
#### a. Constructing the Filters (Kernels)

The CQT is essentially a **filter bank**. We need to construct a separate complex filter (kernel) for every frequency bin $k$.

##### Step A: Determine Window Lengths
First, for each bin $k$, we calculate the specific window length $N_k$ (in samples). This depends on whether we are using CQT or VQT.

* **For CQT ($\gamma = 0$):**
    $$N_k = \frac{f_s}{f_k} \cdot Q$$
* **For VQT ($\gamma > 0$):**
    $$N_k = \left\lceil \frac{f_s \cdot Q}{f_k + \frac{\gamma}{\zeta}} \right\rceil$$

*(Recall that $Q = (2^{1/B} - 1)^{-1}$ and $f_k = f_{min} \cdot 2^{k/B}$)*.

##### Step B: The Time-Domain Kernel Expression
The filter $h_k[n]$ for the $k$-th bin is a complex sinusoid modulated by a window function. It is constructed as follows:

$$h_k[n] = \frac{1}{C_k} \cdot w\left(\frac{n}{N_k}\right) \cdot e^{-j 2 \pi \frac{f_k}{f_s} n}$$

Where:
* **$n$**: The time sample index, centered around zero, typically ranging from $-\lfloor \frac{N_k}{2} \rfloor$ to $+\lfloor \frac{N_k}{2} \rfloor$.
* **$e^{-j 2 \pi \dots}$**: The complex exponential (sinusoid) that "tunes" this filter to detect frequency $f_k$.
* **$w(t)$**: A window function (typically a **Hamming** or **Hann** window) centered at 0. This limits the filter in time and reduces spectral leakage.
* **$C_k$**: A normalization constant (usually the $L_2$ norm or $L_1$ norm of the window) to ensuring energy is preserved across different bin widths.

In implementations like `nnAudio` (used in PESTO), these kernels are **pre-computed** and stored as weights in a 1D Convolutional layer.

---

#### b. Performing the Transform

Once the bank of filters $\{h_k\}$ is constructed for all $k = 1 \dots K$, the transform is performed via **convolution**.

##### The Expression
For an input audio signal $x[n]$, the CQT coefficient $X[k, n]$ for bin $k$ at time $n$ is the result of convolving the signal with the complex conjugate of the time-reversed filter kernel:

$$X[k, n] = \sum_{m} x[m] \cdot h_k^*[m - n]$$

In practice, this is equivalent to running the audio through a 1D Convolutional Neural Network layer where:
* **Input:** The raw audio waveform (size $1 \times T$).
* **Weights:** The pre-computed CQT kernels (size $K \times \text{max}(N_k)$).
* **Output:** The complex CQT spectrogram.

-------

# II. Loss Functions

PESTO minimizes a composite objective function that combines three distinct losses to enforce physical equivariance while preventing model collapse.


#### 1. Equivariance Loss ($\mathcal{L}_{\text{equiv}}$)
**Purpose:** Enforces the geometric property that a pitch shift in the input must result in a proportional shift in the output probability distribution.

Instead of using a decoder, PESTO projects the output distribution $y$ onto a scalar using a deterministic linear form $\phi$. If $y^{(k)}$ is a valid $k$-transposition of $y$, the ratio of their projections must equal $\alpha^k$ (where $\alpha = 2^{1/36}$ in practice).

The loss minimizes the error between the actual projected ratio and the expected ratio using the Huber loss function $h_\tau$ for robustness:

$$\mathcal{L}_{\text{equiv}}(y, y^{(k)}, k) = h_\tau \left( \frac{\phi(y^{(k)})}{\phi(y)} - \alpha^k \right)$$

#### 2. Shifted Cross-Entropy Loss ($\mathcal{L}_{\text{SCE}}$)
**Purpose:** Acts as a regularization term to enforce the shape of the distribution and prevent the model from satisfying equivariance trivially (e.g., by outputting flat distributions).

This loss explicitly compares the original output $y$ against the shifted output $y^{(k)}$. Since a shift of $k$ bins moves some indices out of the viewable frame, these "out-of-bounds" indices are replaced by 0 (masked). This ensures the model is not penalized for pitches that disappear from the frequency range due to the shift.

$$\mathcal{L}_{\text{SCE}}(y, y^{(k)}, k) = \sum_{i=0}^{d-1} y_i \log(y^{(k)}_{i+k})$$

*(Note: Indices $i+k$ that fall outside the valid range $[0, d-1]$ are ignored in the sum)*.

#### 3. Invariance Loss ($\mathcal{L}_{\text{inv}}$)
**Purpose:** Ensures the model predicts pitch based on frequency content rather than timbre or loudness.

We generates augmented views $\tilde{x}$ of the input $x$ using pitch-preserving transforms (gain, additive white noise, or background mixing). The loss then minimizes the standard cross-entropy between the predictions of the original and augmented views.

$$\mathcal{L}_{\text{inv}}(y, \tilde{y}) = \text{CrossEntropy}(y, \tilde{y})$$



## Loss Symmetry & Gradient Stopping

The PESTO loss function incorporates three critical mechanisms to ensure effective SSL: **Symmetry**, **Stop Gradient** and **Loss Weighting**.

#### 1. Why losses should be symmetric
Since PESTO is self-supervised, there is no "ground truth" label. The model learns by comparing two different augmented views of the same input (e.g., $y$ and $\tilde{y}$), and standard Cross-Entropy $\text{Loss}(A, B)$ is directional, it assumes $B$ is the truth and optimizes $A$ to match it. So to treat both views equally, the loss is calculated in both directions and averaged. This ensures the model learns a robust representation regardless of which augmented view is presented as the "target."

$$\text{Loss} = \frac{1}{2} \left[ \underbrace{\mathcal{L}(y, \tilde{y})}_{\text{Predict } y \text{ from } \tilde{y}} + \underbrace{\mathcal{L}(\tilde{y}, y)}_{\text{Predict } \tilde{y} \text{ from } y} \right]$$

#### 2. Why stop gradient is used
The "Stop Gradient" operation is a stability mechanism widely used in Siamese networks (like SimSiam or BYOL) to prevent Model Collapse.

If the network updates its parameters to minimize the distance between $y$ and $\tilde{y}$ simultaneously, it may converge on a "lazy" solution, so the network could learn to output a constant vector (e.g., all zeros or a uniform distribution) for every input. If $y = \tilde{y} = \text{constant}$, the loss is zero, but the model has learned nothing about pitch. That's why we artificially freeze one side of the equation during backpropagation.
  * In the term $\mathcal{L}(y, \text{sg}(\tilde{y}))$, $\tilde{y}$ is treated as a **fixed constant**.
  * The network only updates weights to move $y$ closer to $\tilde{y}$, not to move $\tilde{y}$ closer to $y$.
* **Result:** This prevents the degenerate scenario where both outputs simply "meet in the middle" at a meaningless value, forcing the network to learn meaningful transformations.


#### 3. Adaptive Loss Weighting
If one loss is numerically much larger than the others, the model will focus only on that one and ignore the others, and since we are not sure that the three losses have the same scales and gradients. To balance the three competing objectives, PESTO does not use fixed hyperparameters. Instead, it employs **GradNorm**, a gradient-based normalization algorithm, since the norm of the gradient of each loss can be interpreted as its contribution to the total objective to optimize.. Refer to the two papers: [Taming Transformers for High-Resolution Image Synthesis](https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf) and [Value Function Decomposition for Iterative Design of Reinforcement Learning Agents](https://proceedings.neurips.cc/paper_files/paper/2022/file/4eb2c0adafbe71269f3a772c130f9e53-Paper-Conference.pdf).


## III. Experimental Results & Robustness

my work extended the original PESTO evaluation to include **Environmental Robustness** (Reverberation).

### Robustness to Reverberation

To evaluate how PESTO performs in real-world acoustic environments, we subjected the model to synthetic reverberation. This simulates the effect of sound reflections in a physical space, which can obscure the fundamental frequency.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/reverb_filter.png" title="Comparaison" class="img-fluid" %}
    </div>
</div>

#### Quantitative Analysis

We tested the model using two datasets—**MIR-1K** (singing voice) and **MDB** (musical instruments)—under varying reverb mix levels.

| Mix | RPA (MIR-1K) | RPA (MDB) | RCA (MIR-1K) | RCA (MDB) |
| --- | --- | --- | --- | --- |
| **0.0 (Clean)** | 86.92% | 88.21% | 87.19% | 92.25% |
| **0.3 (Mild)** | 83.56% | 83.28% | 83.83% | 88.62% |
| **0.6 (Heavy)** | **69.32%** | **69.78%** | 70.13% | 76.11% |
| **0.9 (Extreme)** | 59.61% | 62.87% | 60.50% | 69.13% |

* **Stability:** The model is remarkably stable under mild reverb conditions.
* **Degradation:** A sharp performance drop occurs at , where the reflections begin to dominate the direct signal.

#### Qualitative Error Analysis

When examining the predictions at extreme reverb levels, we observed specific failure modes:

<div class="row">
    <div class="col-sm mt-1 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/pesto_0.9.png" title="Comparaison" class="img-fluid" %}
    </div>
</div>

* **Octave Errors:** Reverb tails often create constructive interference at higher harmonics. If the second harmonic becomes more energetic than the fundamental due to reflections, the model may mistakenly track the higher octave.
* **Temporal Smearing:** Reverberation causes spectral energy to persist long after the note has ended. This "smearing" creates misalignment between the actual pitch and the model's prediction.
* **Structural Limitations:** Because PESTO’s architecture relies on **1D-convolutions along the frequency axis**, it processes frames independently. It lacks the **temporal memory** (e.g., recurrent layers or attention) necessary to distinguish between a new note and the "echo" of a previous one.
